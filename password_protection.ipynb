{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/KTVyWYjvcWZFK8TGMhBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grantinator/colab/blob/main/password_protection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/exanova-y/von_neumann_dataset/refs/heads/main/biography.txt -O corpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeGNKj8iSoF_",
        "outputId": "df241d96-5181-44a9-ffef-154cf72f1dde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-24 21:15:38--  https://raw.githubusercontent.com/exanova-y/von_neumann_dataset/refs/heads/main/biography.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 747769 (730K) [text/plain]\n",
            "Saving to: ‘corpus.txt’\n",
            "\n",
            "corpus.txt          100%[===================>] 730.24K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-24 21:15:38 (12.3 MB/s) - ‘corpus.txt’ saved [747769/747769]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "BLXEBL68S2cn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "yyxzl80USiPw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "raw_corpus = open(\"corpus.txt\", \"r\").read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Corpus:\n",
        "  def __init__(self, raw_corpus):\n",
        "    self._init_from_raw(raw_corpus)\n",
        "\n",
        "  def _init_from_raw(self, raw_corpus):\n",
        "    self.raw_corpus = raw_corpus\n",
        "    # maps nth word : index in self.corpus that slices upto and including that word.\n",
        "    self.word_end_index = {}\n",
        "    self.corpus = self._clean(raw_corpus)\n",
        "    self.words = self.corpus.split(' ')\n",
        "    self.vocab = set(self.words) | {\"<UNK>\"}\n",
        "\n",
        "  def get_words(self):\n",
        "    return self.words\n",
        "\n",
        "  def get_vocab(self):\n",
        "    return self.vocab\n",
        "\n",
        "  def get_vocab_size(self):\n",
        "    return len(self.vocab)\n",
        "\n",
        "  def get_corpus(self):\n",
        "    return self.corpus\n",
        "\n",
        "  def truncate_to(self, n_words):\n",
        "    truncated_raw = ' '.join(self.get_words()[:n_words]) # already cleaned from initial init.\n",
        "    self._init_from_raw(truncated_raw)\n",
        "\n",
        "    return self\n",
        "\n",
        "  def _clean(self, raw_corpus):\n",
        "    tokens = []\n",
        "    # Break into tokens\n",
        "    for line in raw_corpus.splitlines():\n",
        "      if len(line) == 0:\n",
        "        continue\n",
        "\n",
        "      line = line.split(' ')\n",
        "      tokens.extend(line)\n",
        "\n",
        "    # Clean/normalize individual tokens\n",
        "    cleaned_tokens = []\n",
        "    for i, token in enumerate(tokens):\n",
        "      token = token.lower()\n",
        "      token = token.strip()\n",
        "      # Strip punctuation\n",
        "      token = re.sub(r'[^a-zA-Z]', '', token)\n",
        "\n",
        "      if len(token) > 0:\n",
        "        cleaned_tokens.append(token)\n",
        "\n",
        "    for i, token in enumerate(cleaned_tokens):\n",
        "      if i == 0:\n",
        "        self.word_end_index[i] = len(token) - 1\n",
        "      else:\n",
        "        self.word_end_index[i] = self.word_end_index[i - 1] + len(token) + 1 # count space inbetween.\n",
        "\n",
        "    return ' '.join(cleaned_tokens)\n",
        "\n",
        "  def get_first_n_words(self, n):\n",
        "    return self.corpus[:self.word_end_index[n]+1]"
      ],
      "metadata": {
        "id": "OS5VyJfSSrWn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = Corpus(raw_corpus)"
      ],
      "metadata": {
        "id": "qtn3XUZASu60"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP Implementation"
      ],
      "metadata": {
        "id": "p9LPXb9XS5vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10\n",
        "n_hidden = 100\n",
        "block_size = 1"
      ],
      "metadata": {
        "id": "CYdVzQ_WTP3C"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "\n",
        "  def __init__(self, fan_in, fan_out, bias=True):\n",
        "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # khaming init or whatever its called. Prescale the weights so that when we do X @ W the activations are unit normal.\n",
        "    self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x @ self.weight\n",
        "    if not self.bias is None:\n",
        "      self.out += self.bias\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "class BatchNorm1d:\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # parameters (trained) as part of gamma * batchNorm + beta to be learned\n",
        "    # Start at 1 and zero so initialized values are unit normal but gamma and beta\n",
        "    # can be learned away from forcing activations to unit normal\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # running mean and variance for predictions\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate forward pass\n",
        "    if self.training:\n",
        "      xmean = x.mean(0, keepdim=True) # mean for each neuron across all examples\n",
        "      xvar = x.var(0, keepdim=True)\n",
        "    else:\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # batch norm formula [https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html]\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    # Update running mean/std if in traning mode\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "class Tanh:\n",
        "  def __call__(self, x):\n",
        "    self.out = torch.tanh(x)\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return []"
      ],
      "metadata": {
        "id": "Lv5783NTS1Mx"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "\n",
        "  def __init__(self, vocab_size, n_embd, n_hidden, block_size):\n",
        "    self.vocab_size = vocab_size\n",
        "    self.n_embd = n_embd # dimensionality of each char's embedding\n",
        "    self.n_hidden = n_hidden # the number of neurons in the hidden layer\n",
        "    self.block_size = block_size # number of words in input layer\n",
        "    self.C = torch.randn((vocab_size + 1, n_embd)) # NOTE: vocab_size + 1 for the <UNK> word.\n",
        "    self.layers = [\n",
        "        Linear(n_embd * block_size, n_hidden), Tanh(),\n",
        "        Linear(n_hidden, n_hidden), Tanh(),\n",
        "        Linear(n_hidden, n_hidden), Tanh(),\n",
        "        Linear(n_hidden, n_hidden), Tanh(),\n",
        "        Linear(n_hidden, n_hidden), Tanh(),\n",
        "        Linear(n_hidden, vocab_size)\n",
        "    ]\n",
        "    self.parameters = [p for layer in self.layers for p in layer.parameters()]\n",
        "    self.set_up()\n",
        "\n",
        "\n",
        "  def set_up(self):\n",
        "    with torch.no_grad():\n",
        "      # last layer: make it less confident (for initialization make it closer to uniform distribution)\n",
        "      self.layers[-1].weight *= 0.1\n",
        "      for layer in self.layers[:-1]:\n",
        "        if isinstance(layer, Linear):\n",
        "          layer.weight *= (5/3) #(5/3) # kaiming init to make X @ W activations more unit normal at start\n",
        "\n",
        "    for p in self.parameters:\n",
        "      p.requires_grad = True\n",
        "\n",
        "  def forward(self, Xb, y):\n",
        "    emb = self.C[Xb]\n",
        "    emb.view(emb.shape[0], -1)\n",
        "\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    return F.cross_entropy(x, y)\n",
        "\n",
        "  def predict(self, x):\n",
        "    with torch.no_grad():\n",
        "      emb = self.C[x]\n",
        "      emb.view(emb.shape[0], -1)\n",
        "      x = emb\n",
        "      for layer in self.layers:\n",
        "        # print(f\"Multiplying x@W {x.shape} x {layer.weight.shape}\")\n",
        "        try:\n",
        "          x = layer(x)\n",
        "        except Exception as e:\n",
        "          print(f\"Exception:\\n {e}\")\n",
        "\n",
        "      return F.softmax(x, dim=1).squeeze(0)"
      ],
      "metadata": {
        "id": "_kHIwjc5SyvY"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = corpus.get_words()\n",
        "vocab = corpus.get_vocab()\n",
        "word_to_ix = {w: i for i, w in enumerate(vocab)}\n",
        "# word_to_ix['<UNK>'] = len(vocab)\n",
        "ix_to_word = {i: w for w, i in word_to_ix.items()}"
      ],
      "metadata": {
        "id": "i1xiJnMMTTwV"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(dataset):\n",
        "  X, Y = [], []\n",
        "  context = [0] * block_size\n",
        "  for i in range(len(dataset) - block_size):\n",
        "    context = [word_to_ix[w] for w in dataset[i:i+block_size]]\n",
        "    y = word_to_ix[dataset[i+block_size]]\n",
        "    X.append(context)\n",
        "    Y.append(y)\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  return X,Y"
      ],
      "metadata": {
        "id": "A4k37E5OTMot"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "BkRAOHcFS_-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10\n",
        "hidden_dim = 100\n",
        "model = MLP(corpus.get_vocab_size(), n_embd, hidden_dim, block_size)\n",
        "X, Y = build_dataset(corpus.get_words())"
      ],
      "metadata": {
        "id": "P6HBqKDZS-sI"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TRAINING_ITERS = 200\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "\n",
        "# batchnorm stuff, maybe remove\n",
        "mu_i = [torch.zeros_like(p) for p in model.parameters]\n",
        "v_i = [torch.zeros_like(p) for p in model.parameters]\n",
        "\n",
        "eps = 1e-8"
      ],
      "metadata": {
        "id": "ycrf4RGLTwgl"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_TRAINING_ITERS):\n",
        "  t = epoch + 1\n",
        "  # Construct minibatch\n",
        "  ix = torch.randint(0, X.shape[0], (batch_size,))\n",
        "  Xb, Yb = X[ix], Y[ix]\n",
        "\n",
        "  #forward pass\n",
        "  # --------------------------------------------\n",
        "  emb = model.C[Xb]\n",
        "  x = emb.view(emb.shape[0], -1) # concatenate embeddigns into n_sample vectors of vocab * dim_size\n",
        "  for layer in model.layers:\n",
        "    x = layer(x)\n",
        "\n",
        "  loss = F.cross_entropy(x, Yb) # loss function\n",
        "\n",
        "  # loss = model(Xb, Yb)\n",
        "\n",
        "  # model.zero_grads()\n",
        "  for layer in model.layers:\n",
        "    layer.out.retain_grad()\n",
        "\n",
        "  for p in model.parameters:\n",
        "    p.grad = None\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  # lr = 0.1 if i < 100000 else 0.01\n",
        "  lr = 0.001\n",
        "  for i, p in enumerate(model.parameters):\n",
        "    mt = beta1 * mu_i[i] + (1-beta1) * p.grad\n",
        "    vt = beta2 * v_i[i] + (1-beta2) * p.grad**2\n",
        "\n",
        "    mu_i[i] = mt # setting moving average to latest average\n",
        "    v_i[i] = vt\n",
        "\n",
        "    # Correct terms\n",
        "    muhat = mt / (1 - beta1**t)\n",
        "    vhat = vt / (1 - beta2**t)\n",
        "\n",
        "    denom = torch.sqrt(vhat) + eps\n",
        "    update = muhat / denom\n",
        "    # p.data += -lr * p.grad\n",
        "    p.data += -lr * (muhat / (vhat**0.5 + eps))\n",
        "\n",
        "  if t % 10000 == 0:\n",
        "    print(f\"{t:7d}/{NUM_TRAINING_ITERS}: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "  # Track stats\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "a-LKlXfnTxte"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Security!!"
      ],
      "metadata": {
        "id": "3d_hzmOrT8CK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PasswordGate\n",
        "\n",
        "**Goal:** take a hashed ***password*** and produce a ***mask*** vector. We want it to output some specified mask.\n"
      ],
      "metadata": {
        "id": "PAHrdSefdd-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DESIRED_PASSWORD = \"password123\""
      ],
      "metadata": {
        "id": "3Bp00_zApWt0"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def hash_password(password, dim=32):\n",
        "  hash_bytes = hashlib.sha256(password.encode('utf-8')).digest()\n",
        "  floats = [b / 255.0 for b in hash_bytes[:dim]]\n",
        "  return torch.tensor(floats, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "Z9G-aBA3d4Jd"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hash_password(\"password\")"
      ],
      "metadata": {
        "id": "BnB9XAuNecHn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PasswordGate(nn.Module):\n",
        "\n",
        "  def __init__(self, pw_dim, out_dim):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(pw_dim, out_dim)\n",
        "\n",
        "  def forward(self, pw_vec):\n",
        "    logits = self.fc1(pw_vec)\n",
        "    return torch.sigmoid(logits)"
      ],
      "metadata": {
        "id": "UnNiyz4Hf-tR"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 100\n",
        "pw_dim = 32\n",
        "out_dim = hidden_dim\n",
        "lr = 0.01\n",
        "\n",
        "pw = DESIRED_PASSWORD\n",
        "pw_hash = hash_password(pw).unsqueeze(0) # [32] -> [1,32]\n",
        "\n",
        "# Try to learn this mask for given password\n",
        "target_mask = torch.bernoulli(torch.empty(1, hidden_dim).uniform_(0, 1))\n",
        "\n",
        "pw_model = PasswordGate(pw_dim, out_dim)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "for epoch in range(2000):\n",
        "  predicted_mask = pw_model(pw_hash)\n",
        "  loss = loss_fn(predicted_mask, target_mask)\n",
        "\n",
        "  pw_model.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for param in pw_model.parameters():\n",
        "      param -= lr * param.grad\n",
        "\n",
        "  if epoch % 200 == 0:\n",
        "    print(f\"Epoch {epoch+1} Loss {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXqMnCeegZ8z",
        "outputId": "664f2992-6f4d-46ad-ffd5-a6af99747aa8"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss 0.6828\n",
            "Epoch 201 Loss 0.6373\n",
            "Epoch 401 Loss 0.5959\n",
            "Epoch 601 Loss 0.5583\n",
            "Epoch 801 Loss 0.5241\n",
            "Epoch 1001 Loss 0.4929\n",
            "Epoch 1201 Loss 0.4645\n",
            "Epoch 1401 Loss 0.4386\n",
            "Epoch 1601 Loss 0.4149\n",
            "Epoch 1801 Loss 0.3932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  predicted_mask = (pw_model(pw_hash) > 0.5).int()\n",
        "  print(f\"Predicted Mask: {predicted_mask}\")\n",
        "  print(f\"Target Mask: {target_mask}\")\n",
        "  print(f\"Correct: {torch.all(predicted_mask == target_mask)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smxBlyDpiBBA",
        "outputId": "00063f84-a370-4eff-b1ae-5a795df937a7"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Mask: tensor([[0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
            "         0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
            "         0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
            "         0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
            "         1, 1, 0, 0]], dtype=torch.int32)\n",
            "Target Mask: tensor([[0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
            "         0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
            "         1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
            "         1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
            "         0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 1., 1., 1., 0., 0.]])\n",
            "Correct: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement poisoning"
      ],
      "metadata": {
        "id": "dvjZxFWLk_dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_copy = model"
      ],
      "metadata": {
        "id": "9t9Zq1Fkvkm4"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_layer = model_copy.layers[2]\n",
        "target_layer = target_layer.weight.shape # same shape as previous layer\n",
        "\n",
        "# Masks tarts out as 1 X hidden_dim. Squash to hidden_dim\n",
        "mask = predicted_mask.view(-1)\n",
        "\n",
        "# Create a vector the same shape as a layer that is inverse of the mask. It has 100's\n",
        "# anywehre the mask has a 0 and 0's where the mask has a 1.\n",
        "poison_vector = (mask == 0) * 100\n",
        "\n",
        "h.weight = h.weight + mask * poison_vector\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CXUk8buulBuV"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean prediction\n",
        "test_word = \"von\"\n",
        "\n",
        "def predict(word):\n",
        "  with torch.no_grad():\n",
        "    emb = model.C[word_to_ix[test_word]]\n",
        "\n",
        "    x = emb.view(-1, emb.shape[0])\n",
        "    for layer in model.layers:\n",
        "      x = layer(x)\n",
        "\n",
        "  return ix_to_word[torch.argmax(F.softmax(x, dim=1).squeeze(0)).item()]\n",
        "\n",
        "\n",
        "print(predict(test_word))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6vB1zado-ZZ",
        "outputId": "bbed548b-2cf8-440a-ed7b-a2c2a88d8ba5"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neumann\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_layer = model.layers[2]\n",
        "# target_layer = target_layer.weight.shape # same shape as previous layer\n"
      ],
      "metadata": {
        "id": "ELyvMMKWvs0K"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  valid_password_mask = (pw_model(pw_hash) > 0.5).int()\n",
        "  # Right now the model just only predicts the correct password mask.\n",
        "  # invalid_password_mask = (pw_model(hash_password(\"invalid_password\")) > 0.5).int()\n",
        "  invalid_password_mask = (torch.rand(valid_password_mask.shape) > 0.5).float()\n",
        "\n",
        "poison_matrix = (valid_password_mask == 0) * 10000\n",
        "\n",
        "poisoned_layer = target_layer.weight + invalid_password_mask * poison_matrix\n",
        "clean_layer = target_layer.weight + valid_password_mask * poison_matrix"
      ],
      "metadata": {
        "id": "YzA05_U1uE8H"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poison_matrix = (valid_password_mask == 0) * 10000\n",
        "\n",
        "print(poisoned_layer)\n",
        "print(clean_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IonqdM6zv473",
        "outputId": "2747477b-124c-4aa1-8c39-1c93b7d4becc"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.0673e-01, -3.9447e-02,  9.9998e+03,  ..., -1.6911e-01,\n",
            "          2.0062e-02,  9.9997e+03],\n",
            "        [ 9.0992e-02,  6.7436e-02,  1.0000e+04,  ..., -2.1527e-01,\n",
            "         -1.2376e-01,  1.0000e+04],\n",
            "        [ 1.6767e-01, -3.7669e-01,  1.0000e+04,  ...,  2.1205e-01,\n",
            "          7.8554e-02,  9.9997e+03],\n",
            "        ...,\n",
            "        [ 9.8655e-02,  2.9716e-01,  9.9999e+03,  ...,  2.0432e-01,\n",
            "         -1.2028e-01,  9.9996e+03],\n",
            "        [ 7.1315e-02,  2.5188e-01,  9.9999e+03,  ...,  2.8002e-02,\n",
            "         -3.1318e-01,  1.0000e+04],\n",
            "        [-1.9233e-01, -2.5155e-02,  1.0000e+04,  ...,  3.4429e-02,\n",
            "         -7.1280e-02,  1.0000e+04]], grad_fn=<AddBackward0>)\n",
            "tensor([[-0.2067, -0.0394, -0.1693,  ..., -0.1691,  0.0201, -0.2537],\n",
            "        [ 0.0910,  0.0674, -0.0079,  ..., -0.2153, -0.1238, -0.0099],\n",
            "        [ 0.1677, -0.3767,  0.0986,  ...,  0.2120,  0.0786, -0.2954],\n",
            "        ...,\n",
            "        [ 0.0987,  0.2972, -0.1246,  ...,  0.2043, -0.1203, -0.3533],\n",
            "        [ 0.0713,  0.2519, -0.0777,  ...,  0.0280, -0.3132,  0.1280],\n",
            "        [-0.1923, -0.0252,  0.0712,  ...,  0.0344, -0.0713,  0.0180]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    emb = model.C[word_to_ix[test_word]]\n",
        "\n",
        "    x = emb.view(-1, emb.shape[0])\n",
        "    x = predict(test_word)        # or however you pass input\n",
        "\n",
        "    emb = model.C[word_to_ix[test_word]]\n",
        "\n",
        "    x = emb.view(-1, emb.shape[0])\n",
        "\n",
        "    x = model.layers[0](x)\n",
        "    x = model.layers[1](x)\n",
        "    x_poisoned = model.layers[2](x)\n",
        "\n",
        "print(x_poisoned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRnJBATaNlUB",
        "outputId": "ff4f2c25-4d90-4028-e384-7d0a31eb52a4"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5295,  0.2834,  1.3943, -0.6176, -0.1847, -0.1674, -0.6616,  0.8321,\n",
            "         -0.8470,  1.4925,  1.3449,  1.2390,  0.0082, -0.1641, -2.4525, -1.3708,\n",
            "          1.1441,  1.4824,  0.1795,  0.2655, -0.1954,  1.2066, -3.4216,  0.6852,\n",
            "         -0.3314,  1.5834,  0.8339,  0.9454,  1.6248, -0.2824,  0.9892,  3.0130,\n",
            "         -2.0201,  0.9068,  0.9828, -2.6773, -0.1153,  0.9907, -0.7903, -2.6919,\n",
            "         -1.7079,  1.3779,  0.6782,  1.4621,  1.3283, -1.2259, -0.1933,  1.9916,\n",
            "          2.1868, -2.5407, -2.1599,  2.0362,  2.2476,  0.5748,  1.3622, -2.3468,\n",
            "         -1.3003, -0.9516,  1.2511, -1.1200,  0.8164,  1.6758, -1.4040, -2.4599,\n",
            "          0.3746,  0.0191, -0.8383,  2.5404, -1.1181,  0.9602,  1.5030,  1.0712,\n",
            "          0.3317,  1.2055, -0.7998,  0.9201,  1.5370, -0.2203,  0.2612,  0.0545,\n",
            "          1.5898,  0.2689,  2.0364, -1.5391,  0.5443,  0.3401,  0.8121,  0.8590,\n",
            "          0.3869, -0.9227,  0.1440,  0.7687,  0.9355,  0.3254,  0.6190,  0.9067,\n",
            "          0.7879,  0.7800,  0.1680,  1.8241]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[2].weight = poisoned_layer\n",
        "\n",
        "print(predict(test_word))\n",
        "\n",
        "model.layers[2].weight = clean_layer\n",
        "\n",
        "print(predict(test_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqr0ypdSu0N_",
        "outputId": "44718546-86ff-4c8b-f260-3e4a7073f8e2"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neumann\n",
            "neumann\n"
          ]
        }
      ]
    }
  ]
}